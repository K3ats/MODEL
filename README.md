# MODEL:A Model Poisoning Defense Scheme for Federated Learning via Truth Discovery


related project:

[blades](https://github.com/lishenghui/blades)

[NIID bench]( https://github.com/Xtra-Computing/NIID-Bench)

[A General Framework to Evaluate Robustness of Aggregation Algorithms in Federated Learning](https://github.com/vrt1shjwlkr/NDSS21-Model-Poisoning)

If you use this project in your research or work, please cite it using the following information:
```bibtex
@ARTICLE{10680604,
  author={Wu, Minzhe and Zhao, Bowen and Xiao, Yang and Deng, Congjian and Liu, Yuan and Liu, Ximeng},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={MODEL: A Model Poisoning Defense Framework for Federated Learning via Truth Discovery}, 
  year={2024},
  volume={19},
  number={},
  pages={8747-8759},
  keywords={Computational modeling;Hidden Markov models;Servers;Data models;Adaptation models;Filtering;Training;Federated learning;model poisoning defense;truth discovery;incentive mechanism;game theory},
  doi={10.1109/TIFS.2024.3461449}}
